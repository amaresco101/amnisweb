{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0def383e-0905-4580-90e9-6d6952cff987",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# End to End Industrial IoT (IIoT) on Azure Databricks \n",
    "## Part 3 - Model Deployment and Inference with Azure ML\n",
    "\n",
    "In the original Databricks exercise, these steps were in Part 2. However the method used for deployment has been deprecated. One of the new methods is used for deployment of the life and power models to web service endpoints. Code is then executed to invoke the life and power models to make predictions. These predictors are then used to optimize the Wind Turbine RPM to maximize power while controlling costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a0af72-2e56-4aa0-a8c2-6809ee754a65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Widgets containing important user IDs, names and keys. \n",
    "dbutils.widgets.text(\"Subscription ID\",\"\",\"Subscription ID\")\n",
    "dbutils.widgets.text(\"Resource Group\",\"\",\"Resource Group\")\n",
    "dbutils.widgets.text(\"Region\",\"\",\"Region\")\n",
    "dbutils.widgets.text(\"Workspace\", \"\", \"Workspace\")\n",
    "dbutils.widgets.text(\"Tenant\", \"\", \"Tenant\")\n",
    "dbutils.widgets.text(\"Client ID\", \"\", \"Client ID\")\n",
    "dbutils.widgets.text(\"Client Secret\", \"\", \"Client Secret\")\n",
    "dbutils.widgets.text(\"Life API Key\", \"\", \"Life API Key\")\n",
    "dbutils.widgets.text(\"Power API Key\", \"\", \"Power API Key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "283371b8-cb76-4bd2-8314-95160d7cdea5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "The pre-requisites are listed below:\n",
    "\n",
    "### Azure Services Required\n",
    "* ADLS Gen 2 Storage account with a container called `iot`\n",
    "* Azure Machine Learning Workspace called `iot`\n",
    "\n",
    "### Azure Databricks Configuration Required\n",
    "* 3-node (min) Databricks Cluster running **DBR 10.4 ML+** and the following libraries:\n",
    " * **MLflow[AzureML]** - PyPI library `azureml-mlflow` version\n",
    " * **Azure Event Hubs Connector for Databricks** - Maven coordinates `com.microsoft.azure:azure-eventhubs-spark_2.12:2.3.21`\n",
    " * **Azure ML Package client library for Python** - PyPI library `azure-ai-ml` version 1.5.0\n",
    " * **MLflow** - PyPI library `mlflow` version 1.30.0\n",
    " * **Azure Machine Learning core packages, modules, and classes** - PyPI library `azureml.core` version 1.47.0\n",
    " * **\n",
    "\n",
    "* The following notebook widgets populated:\n",
    " * `Subscription ID` - subscription ID of your Azure ML Workspace\n",
    " * `Resource Group` - resource group name of your Azure ML Workspace\n",
    " * `Region` - Azure region of your Azure ML Workspace\n",
    " * `Workspace` - Name of the Azure Machine Learning Workspace\n",
    " * `Tenant` - Active Directory Tenant ID for Service Principal\n",
    " * `Client ID` - Active Directory Client ID for Service Principal\n",
    " * `Client Secret` - Active Directory Client Secret for Service Principal\n",
    " * `Life API Key` - Life Prediction service API key\n",
    " * `Power API Key` - Power Prediction service API key\n",
    " * **\n",
    "\n",
    "* **Part 1 Notebook Run to generate and process the data**. \n",
    "* Ensure the following tables have been created:\n",
    " * **turbine_maintenance** - Maintenance dates for each Wind Turbine\n",
    " * **turbine_power** - Hourly power output for each Wind Turbine\n",
    " * **turbine_enriched** - Hourly turbine sensor readinigs (RPM, Angle) enriched with weather readings (temperature, wind speed/direction, humidity)\n",
    " * **gold_readings** - Combined view containing all 3 tables\n",
    "* **\n",
    "* **Part 2 Notebook Run to train models and create predictions table**. \n",
    "* Ensure the following models have been created:\n",
    " * **power_prediction** - Predict power 6 hours ahead for each Wind Turbine\n",
    " * **life_prediction** - Predict the remaining life of a turbine before maintenance is required\n",
    "* Ensure the following tables have been created:\n",
    " * **turbine_power_predictions**\n",
    " * **turbine_life_predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a023eff-ee7f-4a93-b1a7-478d345e77f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify azureml.core is installed\n",
    "!pip show azureml.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c53f1897-6eab-4b19-84eb-c19f52d67671",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify azureml-mlflow is installed\n",
    "!pip show azureml-mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aa02be5-2f13-4692-a736-6b91937aff90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verify azure-ai-ml is installed\n",
    "!pip show azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0e371a7-7341-4fa1-8649-23adb128321a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This is automatically installed\n",
    "!pip show azure.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a09f891-a331-4e1b-a175-35f572ed4693",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries and print out the versions\n",
    "import xgboost as xgb\n",
    "import azureml.mlflow\n",
    "import azureml.core\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "# cell to check for versions\n",
    "print(\"XGBoost: {}\".format(xgb.__version__))\n",
    "print(\"Pandas: {}\".format(np.__version__))\n",
    "print(\"MLFlow: {}\".format(mlflow.__version__))\n",
    "print(\"Matplotlib: {}\".format(matplotlib.__version__))\n",
    "print(\"Scikit-Learn: {}\".format(sklearn.__version__))\n",
    "print(\"azureml-mlflow: {}\".format(azureml.mlflow.__version__))\n",
    "print(\"azureml.core: {}\".format(azureml.core.__version__))\n",
    "print(\"NumPy: {}\".format(np.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3c08821-f9ff-4342-ba44-5c489552cce2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If there is an issue with typing_extensions, uncomment out this cell and run it\n",
    "# from https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-mlflow\n",
    "# import typing_extensions\n",
    "# from importlib import reload\n",
    "# reload(typing_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5940075d-e4fc-4509-b053-61079f239cbb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This cell needs to run each time\n",
    "# Set important id's and keys from widgets\n",
    "\n",
    "subscription_id = dbutils.widgets.get(\"Subscription ID\")\n",
    "workspace = dbutils.widgets.get(\"Workspace\")\n",
    "resource_group = dbutils.widgets.get(\"Resource Group\")\n",
    "tenant_id = dbutils.widgets.get(\"Tenant\")\n",
    "client_id = dbutils.widgets.get(\"Client ID\")\n",
    "client_secret = dbutils.widgets.get(\"Client Secret\")\n",
    "life_api_key = dbutils.widgets.get(\"Life API Key\")\n",
    "power_api_key = dbutils.widgets.get(\"Power API Key\")\n",
    "\n",
    "\n",
    "## BLOB_CONTAINER_NAME = \"iot\"\n",
    "# set the ADLS KEY in the spark configuration\n",
    "## spark.conf.set(f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\", adls_key)\n",
    "\n",
    "# Setup storage locations for all data\n",
    "## ROOT_PATH = f\"abfss://iot@{storage_account}.dfs.core.windows.net/\"\n",
    "\n",
    "# Pyspark and ML Imports\n",
    "import os, json, requests\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import mlflow.xgboost\n",
    "import mlflow.azureml\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "import random, string\n",
    "\n",
    "# Random String generator for ML models served in AzureML\n",
    "random_string = lambda length: ''.join(random.SystemRandom().choice(string.ascii_lowercase) for _ in range(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e14a3cb5-ef94-4bfb-a679-465e5bd70626",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This cell needs to run each time\n",
    "# This is for service principal ml-auth\n",
    "# these values will be picked up by DefaultAzureCredential\n",
    "import os\n",
    "\n",
    "os.environ[\"AZURE_TENANT_ID\"] = tenant_id\n",
    "os.environ[\"AZURE_CLIENT_ID\"] = client_id\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"] = client_secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b343e339-8d4e-4add-bb9b-375c923ec5f8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Configuring models' registry\n",
    "\n",
    "MLflow allows you to segregate the instance where experiments are being tracked from the instance where models' are being tracked (or registered). The first one is referred to **Tracking URI** while the second one is referred as **Registry URI**. By default, both of them are set to the same value, and in Azure Databricks, both of them are set to \"databricks\" meaning that tracking and model registries will happen inside of the MLflow instance that Databricks runs for you.\n",
    "\n",
    "We are going to track the experiments in Azure Databricks, but change so that model registries will be held in Azure ML. This will allow us to manage the model's lifecycle - including deployments - in Azure ML.\n",
    "\n",
    "First we create and connect to an MLClient for our workspace, then we get the Azure MLflow tracking URI which will be used to set the Databricks MLflow registry URI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f39255ec-e6d5-473a-bfed-eaf87c459f5e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This cell needs to be executed each time\n",
    "# From here, each cell requires the previous cell to be executed...you can't just skip any group of cells\n",
    "# Note that this cell outputs sensitive parameter values to the notebook if you print(ml_client)\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "# This will show key ID's in the results - so leave it commented unless you want to verify\n",
    "# print(ml_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6b66ba3-afa6-44d2-ad6c-bec3f2f0ea74",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get the Azure Tracking URI which we will use to set the Databricks Resgistry URI\n",
    "azureml_tracking_uri = ml_client.workspaces.get(\n",
    "    ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "print(azureml_tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43904597-b5f0-4a8e-9c61-97d8c9a97e4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set the tracking URI for Databricks mlflow\n",
    "# remember that mlflow is for Databricks and azureml-mlflow is for Azure ML\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(azureml_tracking_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "436a79e0-9a80-48d7-bad0-2552f4043922",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Registering the model in Azure ML\n",
    "\n",
    "So far, our model is trained and tracked inside of the MLflow instance in Azure Databricks. Now we want to register this model in Azure ML to manage the life cicle there. However, if we try to register the model as we usually do using the syntax `mlflow.register_model(model_uri=f\"runs:/{run.info.run_id}/model\").` you will found an error. The reason why this is happening is related to where runs are being stored.\n",
    "\n",
    "Right now runs are being stored in Azure Databricks and models in Azure ML. If you try to create a registered model from a Run, Azure ML doesn't have any way to guess how to get access to the runs, that are stored in a different service. because of that, you can't use `runs:/` URI for registering models.\n",
    "\n",
    "To overcome this limitation, you have to register the model from the artifacts themselfs, which you can achieve by first downloading them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "687fa5e9-fd67-4689-b734-753f7eff07fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#download artifacts for model runs to use in registering with Azure ML\n",
    "import mlflow\n",
    "\n",
    "#You need to lookup the run id's in Databricks and paste them here \n",
    "#paste in the life prediction run id\n",
    "life_prediction_run_id = \"\" \n",
    "\n",
    "#paste in the power prediction run id\n",
    "power_prediction_run_id = \"\" \n",
    "\n",
    "# access the tracking client\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "# first get it from looking up manually \n",
    "life_model_path = client.download_artifacts(life_prediction_run_id, path=\"model\")\n",
    "power_model_path = client.download_artifacts(power_prediction_run_id, path=\"model\")\n",
    "\n",
    "print(life_model_path)\n",
    "print(power_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96b09830-9870-41ad-b9d4-d68b7be84758",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the two models\n",
    "mlflow.register_model(\n",
    "    model_uri=f\"file://{life_model_path}\", name=\"life_prediction\"\n",
    ")\n",
    "\n",
    "mlflow.register_model(\n",
    "    model_uri=f\"file://{power_model_path}\", name=\"power_prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8eb0ca92-338f-4ba1-900b-6d0341ce36b9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Notice in the code above how the protocol is now `file://` instead of `runs:/`.\n",
    "Now look for model in Azure ML Studio in Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea342d8b-ae40-4a2a-b01c-fe4b17ac8824",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Deploy the model as an online endpoint\n",
    "\n",
    "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
    "\n",
    "To deploy a machine learning service, you usually need:\n",
    "\n",
    "* The model assets (file, metadata) that you want to deploy. You've already registered these assets in Azure ML after downloading from Azure Databricks.\n",
    "* Some code to run as a service. The code executes the model on a given input request. This entry script receives data submitted to a deployed web service and passes it to the model, then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns. With an MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "731e15dc-9a56-4a61-9a24-4105ebb52903",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Create a new online endpoint\n",
    "\n",
    "Now that you have a registered model for and an inference script, it's time to create your online endpoint for both life and power. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20(UUID,%2C%20for%20practical%20purposes%2C%20unique.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "256a1db0-5252-4183-aa8a-a59960b4d9d1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create unique names for our endpoints\n",
    "import uuid\n",
    "\n",
    "# Creating a unique name for the life prediction endpoint\n",
    "life_online_endpoint_name = \"life-endpoint-\" + str(uuid.uuid4())[:8]\n",
    "\n",
    "# Creating a unique name for the power prediction endpoint\n",
    "power_online_endpoint_name = \"power-endpoint-\" + str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86ee234b-34bc-47d9-85d1-ccdf62f6d9f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create the endpoints\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    ")\n",
    "\n",
    "# create an online endpoint\n",
    "life_endpoint = ManagedOnlineEndpoint(\n",
    "    name=life_online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"training_dataset\": \"wind turbine rul\",\n",
    "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
    "    },\n",
    ")\n",
    "\n",
    "life_endpoint = ml_client.online_endpoints.begin_create_or_update(life_endpoint).result()\n",
    "\n",
    "# create an online endpoint\n",
    "power_endpoint = ManagedOnlineEndpoint(\n",
    "    name=power_online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"training_dataset\": \"wind turbine power\",\n",
    "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
    "    },\n",
    ")\n",
    "\n",
    "power_endpoint = ml_client.online_endpoints.begin_create_or_update(power_endpoint).result()\n",
    "\n",
    "print(f\"Endpoint {life_endpoint.name} provisioning state: {life_endpoint.provisioning_state}\")\n",
    "print(f\"Endpoint {power_endpoint.name} provisioning state: {power_endpoint.provisioning_state}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d12e173-e1c6-4b89-a7aa-a54b29bf2cec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Once you've created an endpoint, you can retrieve it as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc55c859-c222-4b70-9e7a-1ed8ffb233c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# verify that we have the correct ml_client\n",
    "life_endpoint = ml_client.online_endpoints.get(name=life_online_endpoint_name)\n",
    "\n",
    "print(\n",
    "    f'Endpoint \"{life_endpoint.name}\" with provisioning state \"{life_endpoint.provisioning_state}\" is retrieved'\n",
    ")\n",
    "\n",
    "power_endpoint = ml_client.online_endpoints.get(name=power_online_endpoint_name)\n",
    "\n",
    "print(\n",
    "    f'Endpoint \"{power_endpoint.name}\" with provisioning state \"{power_endpoint.provisioning_state}\" is retrieved'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98d8fe78-5148-41dd-a53a-dc5c834b7309",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Deploy the model to the endpoint\n",
    "\n",
    "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments. Direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, *blue*, *green*, *red* deployments, which is arbitrary.\n",
    "\n",
    "You can check the **Models** page on Azure ML studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d33d01a-545c-4818-bebb-45c21b818e0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2 model names are life_prediction and power_prediction\n",
    "# Let's pick the latest version of the model\n",
    "latest_life_model_version = max(\n",
    "    [int(m.version) for m in ml_client.models.list(name=\"life_prediction\")]\n",
    ")\n",
    "\n",
    "latest_power_model_version = max(\n",
    "    [int(m.version) for m in ml_client.models.list(name=\"power_prediction\")]\n",
    ")\n",
    "\n",
    "print(f'Life model version is \"{latest_life_model_version}\"')\n",
    "print(f'Power model version is \"{latest_power_model_version}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0a5ba5c-5ead-4e8d-8925-3fb6fa8498d7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Deploy the latest version of the model.  \n",
    "\n",
    "> [!NOTE]\n",
    "> Expect this deployment to take approximately 12 to 18 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6b66d3e-3bcd-4644-a97b-fe11dbdc37ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# picking the model to deploy. Here we use the latest version of our registered model\n",
    "life_model = ml_client.models.get(name=\"life_prediction\", version=latest_life_model_version)\n",
    "\n",
    "\n",
    "# create an online deployment. Change this type to smaller and see how to track running instances/endpoints\n",
    "# changed from STANDARD_DS3_V2\n",
    "blue_life_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=life_online_endpoint_name,\n",
    "    model=life_model,\n",
    "    instance_type=\"STANDARD_F4S_V2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "blue_life_deployment = ml_client.begin_create_or_update(blue_life_deployment).result()\n",
    "\n",
    "# picking the model to deploy. Here we use the latest version of our registered model\n",
    "power_model = ml_client.models.get(name=\"power_prediction\", version=latest_power_model_version)\n",
    "\n",
    "\n",
    "# create an online deployment. Change this type to smaller and see how to track running instances/endpoints\n",
    "# changed from STANDARD_DS3_V2\n",
    "blue_power_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=power_online_endpoint_name,\n",
    "    model=power_model,\n",
    "    instance_type=\"STANDARD_F4S_V2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "blue_power_deployment = ml_client.begin_create_or_update(blue_power_deployment).result()\n",
    "print(blue_life_deployment)\n",
    "print(blue_power_deployment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4188277-6c93-42d4-a320-3c613426f2c2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Call with code suggested in \"Consume\" tab of ML Studio adapted from original Wind Turbine Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7245215c-120b-4e19-a6a1-53bedab88a90",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "#uri's are blue_power_deployment, blue_life_deployment\n",
    "#keys are life_api_key, power_api_key\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "def score_data(uri, key, data):\n",
    "\n",
    "  if not key:\n",
    "    raise Exception(\"A key should be provided to invoke the endpoint\")\n",
    "  \n",
    "  # The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "  # Remove this header to have the request observe the endpoint traffic rules\n",
    "  headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ key), 'azureml-model-deployment': 'blue' }\n",
    "  body = str.encode(json.dumps(data))\n",
    "  req = urllib.request.Request(uri, body, headers)\n",
    "\n",
    "  try:\n",
    "      response = urllib.request.urlopen(req)\n",
    "\n",
    "      result = response.read()\n",
    "      #print(result)\n",
    "      return(result)\n",
    "  except urllib.error.HTTPError as error:\n",
    "      print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "      # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "      print(error.info())\n",
    "      print(error.read().decode(\"utf8\", 'ignore'))\n",
    "      # is there something better to return ? \n",
    "      return(\"\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "861e5b21-1ff1-4b2d-b7b5-d20f8b918b8b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Test calls to service\n",
    "#uri's are blue_power_deployment, blue_life_deployment\n",
    "#keys are life_api_key, power_api_key\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data =  {\n",
    "  \"input_data\": {\n",
    "    \"columns\": [\n",
    "      \"angle\",\n",
    "      \"rpm\",\n",
    "      \"temperature\",\n",
    "      \"humidity\",\n",
    "      \"windspeed\",\n",
    "      \"power\",\n",
    "      \"age\"\n",
    "    ],\n",
    "    \"index\": [1,7],\n",
    "    \"data\": [[8,6,25,50,5,150,10]]\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# get keys in case they were recently entered\n",
    "life_api_key = dbutils.widgets.get(\"Life API Key\")\n",
    "power_api_key = dbutils.widgets.get(\"Power API Key\")\n",
    "\n",
    "# we get the scoring_uri from each endpoint that we saved above when endpoints were created : power_endpoint, life_endpoint\n",
    "print(f'Current Operating Parameters: {data}')\n",
    "print(f'Predicted power (in kwh) from model: {score_data(power_endpoint.scoring_uri, power_api_key, data)}')\n",
    "print(f'Predicted remaining life (in days) from model: {score_data(life_endpoint.scoring_uri, life_api_key, data)}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1658680-c178-4e93-8ee3-dd3936dfb0c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Asset Optimization\n",
    "We can now identify the optimal operating conditions for maximizing power output while also maximizing asset useful life. \n",
    "\n",
    "\\\\(Revenue = Price\\displaystyle\\sum_1^{365} Power_t\\\\)\n",
    "\n",
    "\\\\(Revenue = {365 * } Price \\displaystyle\\sum_1^{24} Power_t \\\\)\n",
    "\n",
    "\\\\(Cost = {365 \\over Life_{rpm}} Price \\displaystyle\\sum_1^{24} Power_t \\\\)\n",
    "\n",
    "\\\\(Profit = Revenue - Cost\\\\)\n",
    "\n",
    "\\\\(Power_t\\\\) and \\\\(Life\\\\) will be calculated by scoring many different RPM values in AzureML. The results can be visualized to identify the RPM that yields the highest profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "409fa5ed-fa2d-43ab-b14b-2e7cd8345073",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "#uri's are blue_power_deployment, blue_life_deployment\n",
    "#keys are life_api_key, power_api_key\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "def create_packet (angle, rpm, temp, hum, wind, power, age):\n",
    "  # Request data goes here\n",
    "  # The example below assumes JSON formatting which may be updated\n",
    "  # depending on the format your endpoint expects.\n",
    "  # More information can be found here:\n",
    "  # https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "  data =  {\n",
    "    \"input_data\": {\n",
    "      \"columns\": [\n",
    "        \"angle\",\n",
    "        \"rpm\",\n",
    "        \"temperature\",\n",
    "        \"humidity\",\n",
    "        \"windspeed\",\n",
    "        \"power\",\n",
    "        \"age\"\n",
    "      ],\n",
    "      \"index\": [1,7],\n",
    "      \"data\": [[angle, rpm, temp, hum, wind, power, age]]\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return(data)\n",
    "\n",
    "\n",
    "# Iterate through 14 different RPM configurations and capture the predicted power and remaining life at each RPM\n",
    "results = []\n",
    "for rpm in range(1,15):\n",
    "  data = create_packet(8,rpm,25,50,5,150,10)\n",
    "  expected_power = score_data(power_endpoint.scoring_uri, power_api_key, data)[0]\n",
    "  data['power'] = expected_power\n",
    "  expected_life = -score_data(life_endpoint.scoring_uri, life_api_key, data)[0]\n",
    "  results.append((rpm, expected_power, expected_life))\n",
    "  \n",
    "# Calculate the Revenue, Cost and Profit generated for each RPM configuration\n",
    "optimization_df = pd.DataFrame(results, columns=['RPM', 'Expected Power', 'Expected Life'])\n",
    "optimization_df['Revenue'] = optimization_df['Expected Power'] * 24 * 365\n",
    "optimization_df['Cost'] = optimization_df['Expected Power'] * 24 * 365 / optimization_df['Expected Life']\n",
    "optimization_df['Profit'] = optimization_df['Revenue'] + optimization_df['Cost']\n",
    "\n",
    "display(optimization_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee2f08fb-6a0d-4b09-b92d-1fe7ddcab8bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### The optimal operating parameters for WindTurbine-1 given the specified weather conditions is 11 RPM for generating a maximum profit of $1.4M! Your results may vary due to the random nature of the sensor readings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e87b2f78-9a86-4a3b-ba01-325d48e94bb5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You can view your model, it's deployments and URL endpoints by navigating to https://ml.azure.com/.\n",
    "\n",
    "<img src=\"https://sguptasa.blob.core.windows.net/random/iiot_blog/iiot_azureml.gif\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0c2b398-3a9d-48f1-b7b1-c5039ecbf438",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Clean up resources - delete endpoints\n",
    "\n",
    "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
    "\n",
    "\n",
    "> [!NOTE]\n",
    "> Expect this step to take approximately 6 to 8 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ee80412-a718-427d-8d50-0ab096590766",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(life_online_endpoint_name)\n",
    "print(power_online_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "029c1f3a-76a2-48e8-a89f-46b60694dc58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Delete the endpoints running our models as services\n",
    "ml_client.online_endpoints.begin_delete(name=life_online_endpoint_name)\n",
    "ml_client.online_endpoints.begin_delete(name=power_online_endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 649532846549294,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2,
    "widgetLayout": []
   },
   "notebookName": "IIoT End-to-End - Fix (Pt 3)",
   "widgets": {
    "Client ID": {
     "currentValue": "",
     "nuid": "037f39fb-75cf-4639-b3d3-9cdefc3c9129",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Client ID",
      "name": "Client ID",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Client Secret": {
     "currentValue": "",
     "nuid": "3d8713fc-f091-407f-85c7-5e26d0a5701d",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Client Secret",
      "name": "Client Secret",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Life API Key": {
     "currentValue": "",
     "nuid": "1884080c-6337-4966-a17d-426ecf648390",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Life API Key",
      "name": "Life API Key",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Power API Key": {
     "currentValue": "",
     "nuid": "10b93c4f-89be-458e-bf3f-22b21148f8a2",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Power API Key",
      "name": "Power API Key",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Region": {
     "currentValue": "",
     "nuid": "e86b58f5-57be-4375-b7b4-de202ba8a254",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Region",
      "name": "Region",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Resource Group": {
     "currentValue": "",
     "nuid": "49ea4ef6-5ad5-481c-9276-1613048f7295",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Resource Group",
      "name": "Resource Group",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Subscription ID": {
     "currentValue": "",
     "nuid": "7a6dac80-ef48-46a1-aa11-433530ee31b4",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Subscription ID",
      "name": "Subscription ID",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Tenant": {
     "currentValue": "",
     "nuid": "de308fb7-e8ab-4db7-a627-4aa543b174e7",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Tenant",
      "name": "Tenant",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    },
    "Workspace": {
     "currentValue": "",
     "nuid": "08c390d5-e667-402e-af26-9f39afe6f6cb",
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Workspace",
      "name": "Workspace",
      "options": {
       "widgetType": "text",
       "validationRegex": null
      }
     }
    }
   }
  },
  "name": "IIoT End-to-End",
  "notebookId": 1335585283234210
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
